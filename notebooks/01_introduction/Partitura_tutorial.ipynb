{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blessed-heavy",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CPJKU/partitura_tutorial/blob/main/notebooks/01_introduction/Partitura_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-immigration",
   "metadata": {},
   "source": [
    "# An Introduction to Symbolic Music Processing with Partitura\n",
    "\n",
    "Partitura is python 3 package for symbolic music processing developed and maintained at CP JKU Linz (and other contributors). It's intended to give a lightweight musical part representation that makes many score properties easily accessible for a variety of tasks. Furthermore, it's a very useful I/O utility to parse computer formats of symbolic music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-communication",
   "metadata": {
    "id": "3tvQmcSB7rrL"
   },
   "source": [
    "## 1. Install and import\n",
    "\n",
    "Partitura is available in github https://github.com/CPJKU/partitura\n",
    "\n",
    "You can install it with `pip install partitura`.\n",
    "\n",
    "However if you are interested in features that still have to be officially released, it's better to install the develop branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-quarterly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PeabdL1k7YC4",
    "outputId": "fcb7d1be-27a1-4c79-c5d3-8cbfa54cae44",
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install partitura\n",
    "    ! pip install partitura\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impressed-principle",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [3], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpartitura\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpt\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      8\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKMP_DUPLICATE_LIB_OK\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import partitura as pt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-italian",
   "metadata": {
    "id": "CX8wCxyK7emp"
   },
   "source": [
    "#### Dataset for this tutorial\n",
    "\n",
    "In this tutorial we are going to use the [Vienna 4x22 Corpus](https://repo.mdw.ac.at/projects/IWK/the_vienna_4x22_piano_corpus/index.html) which consists of performances of 4 classical piano pieces, which have been aligned to their corresponding scores.\n",
    "\n",
    "The dataset contains:\n",
    "\n",
    "* Scores in MusicXML format (4 scores)\n",
    "* Performances in MIDI files (88 in total, 22 performances per piece, each by a different pianist)\n",
    "* Score to performance alignments in Match file format (88 in total one file per performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the dataset\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/CPJKU/vienna4x22.git\n",
    "    DATASET_DIR = \"./vienna4x22\"\n",
    "    MUSICXML_DIR = os.path.join(DATASET_DIR, 'musicxml')\n",
    "    MIDI_DIR = os.path.join(DATASET_DIR, 'midi')\n",
    "    MATCH_DIR = os.path.join(DATASET_DIR, 'match')\n",
    "else:\n",
    "    import sys, os\n",
    "    sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), \"utils\"))\n",
    "    from load_data import init_dataset\n",
    "    DATASET_DIR = init_dataset()\n",
    "    MUSICXML_DIR = os.path.join(DATASET_DIR, 'musicxml')\n",
    "    MIDI_DIR = os.path.join(DATASET_DIR, 'midi')\n",
    "    MATCH_DIR = os.path.join(DATASET_DIR, 'match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-helena",
   "metadata": {},
   "source": [
    "## 2. Loading and Exporting Files\n",
    "\n",
    "One of the main use cases of partitura is to load and export common symbolic music formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-better",
   "metadata": {},
   "source": [
    "### Supported Formats\n",
    "\n",
    "#### Reading\n",
    "\n",
    "##### Symbolic Scores\n",
    "\n",
    "These methods return `Score` objects.\n",
    "\n",
    "| Format              | Method| Notes                                                                                                                           |\n",
    "|:--------------------|:---|:--------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Any Symbolic Format | `partitura.load_score` | (MIDI, MusicXML, MIDI, MEI, Kern)                                                                                               |\n",
    "| MusicXML            | `partitura.load_musicxml`|                                                                                                                                 |\n",
    "| MIDI                | `partitura.load_score_midi`| Pitch spelling, key signature (optional) and other information is inferred with methods in `partitura.musicanalysis`.\n",
    "| MEI                 | `partitura.load_mei`|\n",
    "| Humdrum Kern        | `partitura.load_kern`|\n",
    "| MuseScore           |`partitura.load_via_musescore`| Requires [MuseScore](https://musescore.org/en). Loads all formats supported by MuseScore. Support on Windows is still untested.\n",
    "\n",
    "##### Symbolic Performances\n",
    "\n",
    "These methods return a `Performance`.\n",
    "\n",
    "|Format| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|MIDI|`partitura.load_performance_midi`| Loads MIDI file as a performance, including track, channel and program information. Time signature and tempo information are only used to compute the time of the MIDI messages in seconds. Key signature information is ignored\n",
    "\n",
    "##### Alignments\n",
    "\n",
    "These methods return score-to-performance alignments (discussed in another notebook).\n",
    "\n",
    "|Format| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|Match file| `partitura.load_match`| Returns alignment, a performance as `PerformedPart` and optionally a `Part`. See usage below.\n",
    "|Nakamura et al. corresp file | `partitura.load_nakamuracorresp`|\n",
    "|Nakamura et al. match file| `partitura.load_nakamuramatch`|\n",
    "\n",
    "#### Writing\n",
    "\n",
    "##### Symbolic Scores\n",
    "\n",
    "|Format| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|MusicXML| `partitura.save_musicxml`|\n",
    "|MIDI| `partitura.save_score_midi`| Includes Key signature, time signature and tempo information.\n",
    "\n",
    "##### Symbolic Performances\n",
    "|Format| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|MIDI|`partitura.save_performance_midi`| Does not include key signature or time signature information\n",
    "\n",
    "##### Alignments\n",
    "\n",
    "|Format| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|Match file| `partitura.save_match`| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98b602",
   "metadata": {},
   "source": [
    "## 3. Internal Representations\n",
    "\n",
    "### 3.0 The Score Object\n",
    "\n",
    "Score loading functions return a ```Score``` object. It's a wrapper storing score metadata such as composer and piece as well as all musical material in the score. At the same time it acts as an iterator of contained  ```Part``` objects.\n",
    "\n",
    "### 3.1 The Part Object\n",
    "\n",
    "The ```Part``` object is the central object of partitura. Its name stems from musicxml parts and usually a single instrument.\n",
    "- it is a timeline object\n",
    "- time is measured in divs\n",
    "- its elements are timed objects, i.e. they have a starting time and an ending time\n",
    "- external score files are loaded into a part\n",
    "- parts can be exported into score files\n",
    "- it contains many useful methods related to its properties\n",
    "\n",
    "Here's a visual representation of the ```Part``` object representing the first measure of Chopin's Nocturne Op. 9 No. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754b952",
   "metadata": {},
   "source": [
    "![Timeline_chopin2.png](https://github.com/CPJKU/partitura_tutorial/raw/main/static/Timeline_chopin2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9179e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_musicxml = pt.EXAMPLE_MUSICXML\n",
    "part = pt.load_musicxml(path_to_musicxml)[0] # we access the first (and sole) part of this score by indexing the returned score\n",
    "print(part.pretty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a18d5",
   "metadata": {},
   "source": [
    "![score_example.png](https://github.com/CPJKU/partitura_tutorial/raw/main/static/score_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bae1ed",
   "metadata": {},
   "source": [
    "### 3.2 Notes\n",
    "\n",
    "Each ```Part``` object contains a list notes. Notes inherit from the ```TimedObject``` class. Like all ```TimedObjects``` they contain a (possibly coincident) start time and end time, encoded as ```TimePoint``` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423aac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "part.notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a929369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to print all note object attributes\n",
    "# dir(part.notes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2287849",
   "metadata": {},
   "source": [
    "You can create notes (without timing information) and then add it to a part by specifying start and end times (in divs!). Use each note object only once! You can remove notes from a part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8293c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_note = pt.score.Note(id='n04', step='A', octave=4, voice=1)\n",
    "part.add(a_new_note, start=3, end=15)\n",
    "# print(part.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "part.remove(a_new_note)\n",
    "# print(part.pretty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8649483",
   "metadata": {},
   "source": [
    "### 3.3 Converting from divs to musical units and back\n",
    "\n",
    "Integer divs are useful for encoding scores but unwieldy for human readers. Partitura offers a variety of ```*unit*_maps``` from the timeline unit \"div\" to musical units such as \"beats\" (in two different readings) or \"quarters\". For the inverse operation the corresponding ```inv_*unit*_map``` exist as well. Quarter to div ratio is a fixed value for a ```Part``` object, but units like beats might change with time signature, so these ```maps``` are implemented as ```Part``` methods.\n",
    "\n",
    "Let's look at how to get the ending position in beats of the last note in our example ```Part```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95eb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "part.beat_map(part.notes[0].end.t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f079345",
   "metadata": {},
   "source": [
    "### Timeline maps\n",
    "\n",
    "For several TimedObjects partitura offers convenient ```maps``` that return the object at a position, usually given in divs. Other musical information such as key and time signature is valid for a segment of the score but only encoded in one location. ```Maps``` also retrieve the \"currently active\" time or key signature at any score position.\n",
    "\n",
    "|Returns| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|Time Signature | `part.time_signature_map`|return a triple of beats, beat_type, and musical_beats|\n",
    "|Key Signature | `part.key_signature_map`||\n",
    "|Measure |  `part.measure_map`| returns the start and end point of the current measure |\n",
    "|Measure Number|  `part.measure_number_map`||\n",
    "|Metrical Position|  `part.metrical_position_map`||\n",
    "|Divs -> Beat|  `part.beat_map`||\n",
    "|Beat -> Divs|  `part.inv_beat_map`||\n",
    "|Divs -> Quarters|  `part.quarter_map`||\n",
    "|Quarter -> Divs|  `part.inv_quarter_map`||\n",
    "|Quarter Durations|  `part.quarter_duration_map`||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d6ae9",
   "metadata": {},
   "source": [
    "### 3.4 Iterating over arbitrary musical objects in a part\n",
    "\n",
    "Each ```Part``` object contains a central method ```iter_all``` to iterate over all instances of the ```TimedObject``` class or its subclasses of a part. The ```iter_all``` method returns an iterator and takes five optional parameters: \n",
    "- A ```TimedObject``` subclass whose instances are returned. You can find them all in the partitura/partitura/score.py file. Default is all classes.\n",
    "- A ```include_subclasses``` flag. If true, instances of subclasses are returned too. E.g. ``` part.iter_all(pt.score.TimedObject, include_subclasses=True)``` returns all objects or ```part.iter_all(pt.score.GenericNote, include_subclasses=True)``` returns all notes (grace notes, standard notes)\n",
    "- A start time in divs to specify the search interval (default is beginning of the part)\n",
    "- An end time in divs to specify the search interval (default is end of the part)\n",
    "- A ```mode``` parameter to define whether to search for starting or ending objects, defaults to starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74943a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in part.iter_all(pt.score.Measure):\n",
    "    print(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in part.iter_all(pt.score.GenericNote, include_subclasses=True, start=0, end=24):\n",
    "    print(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0e97b",
   "metadata": {},
   "source": [
    "### 3.5 TimedObject list retrieval\n",
    "\n",
    "For several TimedObjects partitura offers convenient retrieval functions that return the a list of that object without having to use the general `part.iter_all`.\n",
    "\n",
    "\n",
    "|Returns| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|Notes | `part.notes`| |\n",
    "|Tied Notes | `part.notes_tied`| Tied notes are merged into a single sounding note|\n",
    "|Measures |  `part.measures`||\n",
    "|Rests|  `part.rests`||\n",
    "|Repeats|  `part.repeats`||\n",
    "|Key Signatures|  `part.key_sigs`||\n",
    "|Time Signatures|  `part.time_sigs`||\n",
    "|Dynamics|  `part.dynamics`| Dynamics markings in the score|\n",
    "|Articulations|  `part.articulations`|Articulation markings in the score|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1455a5f",
   "metadata": {},
   "source": [
    "### 3.6 Example: Adding a new measure and a note at its downbeat\n",
    "\n",
    "Let's use class retrieval, time mapping, and object creation together and add a new measure with a single beat-length note at its downbeat. This code works even if you know nothing about the underlying score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe430921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the last measure position, time signature and beat length in divs\n",
    "measures = [m for m in part.iter_all(pt.score.Measure)]\n",
    "last_measure_number = measures[-1].number\n",
    "append_measure_start =  measures[-1].end.t \n",
    "Last_measure_ts = part.time_signature_map(append_measure_start)\n",
    "\n",
    "Last_measure_ts = part.time_signature_map(append_measure_start)\n",
    "one_beat_in_divs_at_the_end = append_measure_start - part.inv_beat_map(part.beat_map(append_measure_start)-1)\n",
    "append_measure_end = append_measure_start +  one_beat_in_divs_at_the_end*Last_measure_ts[0]\n",
    "\n",
    "# add a measure\n",
    "a_new_measure = pt.score.Measure(number = last_measure_number+1)\n",
    "part.add(a_new_measure, start=append_measure_start, end=append_measure_end)\n",
    "# add a note\n",
    "a_new_note = pt.score.Note(id='n04', step='A', octave=4, voice=1)\n",
    "part.add(a_new_note, start=append_measure_start, end=append_measure_start+one_beat_in_divs_at_the_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d738a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(part.pretty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59324566",
   "metadata": {},
   "source": [
    "### 3.8 The Performance Object\n",
    "\n",
    "Performance loading functions return a ```Performance``` object. It's a wrapper storing performance metadata as well as all information of a MIDI file. At the same time it acts as an iterator of contained  ```PerformedPart``` objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e4c8b",
   "metadata": {},
   "source": [
    "### 3.9 The PerformedPart Object\n",
    "\n",
    "The ```PerformedPart``` class is a wrapper for MIDI tracks. Its structure is much simpler than the ```Part``` object's:\n",
    "- a notes property that consists of list of MIDI notes as dictionaries\n",
    "- a controls property that consists of list of MIDI CC messages\n",
    "- some more utility methods and properties, such as program changes, note array, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_midifile = pt.EXAMPLE_MIDI\n",
    "# as for scores we index the performance to retrieve the first (and sole) performedpart\n",
    "performedpart = pt.load_performance_midi(path_to_midifile)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3090d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "performedpart.notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8c482",
   "metadata": {},
   "source": [
    "### 3.10 Example: Cats on Keyboards\n",
    "\n",
    "Now that we know the basics of partitura internals we use some randomization to create random scores, that are nevertheless fully specified and exportable to musicxml."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332ca5c",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/CPJKU/partitura_tutorial/raw/main/static/catonkeyboard.png\" alt=\"Cat On Keyboard\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def addnote(midipitch, part, voice, start, end, idx):\n",
    "    \"\"\"\n",
    "    adds a single note by midipitch to a part\n",
    "    \"\"\"\n",
    "    step, alter, octave = pt.utils.music.midi_pitch_to_pitch_spelling(midipitch)\n",
    "\n",
    "    part.add(pt.score.Note(id='n{}'.format(idx), step=step, \n",
    "                        octave=int(octave), alter=alter, voice=voice, staff=int((voice-1)%2+1)),\n",
    "                        start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 200\n",
    "p = pt.score.Part('CoK', 'Cat on Keyboard', quarter_duration=8)\n",
    "dur = np.random.randint(1,20, size=(4,l+1))\n",
    "ons = np.cumsum(dur, axis = 1)\n",
    "pitch = np.row_stack((np.random.randint(20,40, size=(1,l+1)),\n",
    "                      np.random.randint(60,80, size=(1,l+1)),\n",
    "                      np.random.randint(40,60, size=(1,l+1)),\n",
    "                      np.random.randint(40,60, size=(1,l+1))\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f03a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(l):\n",
    "    for j in range(4):\n",
    "        addnote(pitch[j,k], p, j+1, ons[j,k], ons[j,k]+dur[j,k+1], \"v\"+str(j)+\"n\"+str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanitize the part\n",
    "p.add(pt.score.TimeSignature(4, 4), start=0)\n",
    "p.add(pt.score.Clef(1, \"G\", line = 3, octave_change=0),start=0)\n",
    "p.add(pt.score.Clef(2, \"F\", line = 2, octave_change=0),start=0)\n",
    "pt.score.add_measures(p)\n",
    "pt.score.tie_notes(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834582d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.save_score_midi(p, \"CatPerformance.mid\", part_voice_assign_mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.save_musicxml(p, \"CatScore.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f2fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pt.utils.compute_pianoroll(p)\n",
    "fig, ax = plt.subplots(1, figsize=(8, 2))\n",
    "ax.imshow(pr.toarray()[15:85,:500], origin=\"lower\", cmap='gray', interpolation='nearest', aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c266150",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 11025\n",
    "\n",
    "audio_p = pt.utils.synth.synthesize(note_info=p, samplerate=SAMPLE_RATE, harmonic_dist=10, bpm=180)\n",
    "ipd.display(ipd.Audio(data=audio_p, rate=SAMPLE_RATE, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-gathering",
   "metadata": {},
   "source": [
    "## 4. Extracting Information from Scores and Performances\n",
    "\n",
    "For many MIR tasks we need to extract specific information out of scores or performances. \n",
    "Two of the most common representations are **note arrays** and **piano rolls**. \n",
    "\n",
    "**Note that there is some overlap in the way that these terms are used.**\n",
    "\n",
    "Partitura provides convenience methods to extract these common features in a few lines!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Note Arrays\n",
    "\n",
    "A **note array** is a 2D array in which each row represents a note in the score/performance and each column represents different attributes of the note.\n",
    "\n",
    "In partitura, note arrays are [structured numpy arrays](https://numpy.org/devdocs/user/basics.rec.html), which are ndarrays in which each \"column\" has a name, and can be of different datatypes.\n",
    "This allows us to hold information that can be represented as integers (MIDI pitch/velocity), floating point numbers (e.g., onset time) or strings (e.g., note ids).\n",
    "\n",
    "In this tutorial we are going to cover 3 main cases\n",
    "\n",
    "* Getting a note array from `Part` and `PerformedPart` objects\n",
    "* Extra information and alternative ways to generate a note array\n",
    "* Creating a custom note array from scratch from a `Part` object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-psychology",
   "metadata": {},
   "source": [
    "#### 4.1.1. Getting a note array from `Part` and `PerformedPart` objects\n",
    "\n",
    "##### Getting a note array from `Part`  or  `Score`  objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note array from a score\n",
    "\n",
    "# Path to the MusicXML file\n",
    "score_fn = os.path.join(MUSICXML_DIR, 'Chopin_op38.musicxml')\n",
    "\n",
    "# Load the score into a `Score` object\n",
    "score = pt.load_musicxml(score_fn)\n",
    "\n",
    "# Get note array. Calling note arrays from scores will merge the contained parts' note arrays into one.\n",
    "score_note_array = score.note_array() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-whole",
   "metadata": {},
   "source": [
    "It is that easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see the first notes in this note array\n",
    "print(score_note_array[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-publicity",
   "metadata": {},
   "source": [
    "![example_note_array-2.png](https://raw.githubusercontent.com/CPJKU/partitura_tutorial/main/static/example_note_array.png)\n",
    "\n",
    "By default, Partitura includes some of the most common note-level information in the note array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_note_array.dtype.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-practice",
   "metadata": {},
   "source": [
    "* `onset_beat` is the onset time in beats (as indicated by the time signature). In partitura, negative onset times in beats represent pickup measures. Onset time 0 is the start of the first measure.\n",
    "* `duration_beat` is the duration of the note in beats\n",
    "* `onset_quarter` is the onset time of the note in quarters (independent of the time signature). Similarly to onset time in beats, negative onset times in quarters represent pickup measures and onset time 0 is the start of the first measure.\n",
    "* `duration_quarter`is the duration of the note in quarters\n",
    "* `onset_div` is the onset of the note in *divs*, which is generally a number that allows to represent the note position and duration losslessly with integers. In contrast to onset time in beats or quarters, onset time in divs always start at 0 at the first \"element\" in the score (which might not necessarily be a note).\n",
    "* `duration_div` is the duration of the note in divs.\n",
    "* `pitch` is the MIDI pitch (MIDI note number) of the note\n",
    "* `voice` is the voice of the note (in polyphonic music, where there can be multiple notes at the same time)\n",
    "* `id` is the note id (as appears in MusicXML or MEI formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-baseball",
   "metadata": {},
   "source": [
    "##### Getting a note array from a  `PerformedPart`\n",
    "\n",
    "In a similar way, we can obtain a note array from a MIDI file in a few lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note array from a performance\n",
    "\n",
    "# Path to the MIDI file\n",
    "performance_fn = os.path.join(MIDI_DIR, 'Chopin_op38_p01.mid')\n",
    "\n",
    "# Loading the file to a PerformedPart\n",
    "performance = pt.load_performance_midi(performance_fn)\n",
    "\n",
    "# Get note array!\n",
    "performance_note_array = performance.note_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-equity",
   "metadata": {},
   "source": [
    "Since performances contain have other information not included in scores, the default fields in the note array are a little bit different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_note_array.dtype.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-generator",
   "metadata": {},
   "source": [
    "* `onset_sec` is the onset time of the note in seconds. Onset time in seconds is always $\\geq 0$ (otherwise, the performance would violate the laws of physics ;)\n",
    "* `duration_sec` is the duration of the note in seconds\n",
    "* `pitch` is the MIDI pitch\n",
    "* `velocity` is the MIDI velocity\n",
    "* `track` is the track number in the MIDI file\n",
    "* `channel` is the channel in the MIDI file\n",
    "* `id` is the ID of the notes (automatically generated for MIDI file according to onset time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_note_array[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-prescription",
   "metadata": {},
   "source": [
    "We can also create a `PerformedPart` directly from a note array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_array = np.array(\n",
    "    [(60, 0, 2, 40),\n",
    "     (65, 0, 1, 15),\n",
    "     (67, 0, 1, 72),\n",
    "     (69, 1, 1, 90),\n",
    "     (66, 2, 1, 80)],\n",
    "    dtype=[(\"pitch\", \"i4\"),\n",
    "           (\"onset_sec\", \"f4\"),\n",
    "           (\"duration_sec\", \"f4\"),\n",
    "           (\"velocity\", \"i4\"),\n",
    "          ]\n",
    ")\n",
    "\n",
    "# Note array to `PerformedPart`\n",
    "performed_part = pt.performance.PerformedPart.from_note_array(note_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-dealer",
   "metadata": {},
   "source": [
    "We can then export the `PerformedPart` directly to a MIDI file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as MIDI file\n",
    "# pt.save_performance_midi(performed_part, \"example.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-taxation",
   "metadata": {},
   "source": [
    "#### 4.1.2. Extra information and alternative ways to generate a note array\n",
    "\n",
    "Sometimes we require more information in a note array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_score_note_array = pt.utils.music.ensure_notearray(\n",
    "    score,\n",
    "    include_pitch_spelling=True, # adds 3 fields: step, alter, octave \n",
    "    include_key_signature=True, # adds 2 fields: ks_fifths, ks_mode\n",
    "    include_time_signature=True, # adds 2 fields: ts_beats, ts_beat_type \n",
    "    include_metrical_position=True, # adds 3 fields: is_downbeat, rel_onset_div, tot_measure_div\n",
    "    include_grace_notes=True # adds 2 fields: is_grace, grace_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_score_note_array.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-courage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(extended_score_note_array[['id', \n",
    "                                 'step', \n",
    "                                 'alter', \n",
    "                                 'octave', \n",
    "                                 'ks_fifths', \n",
    "                                 'ks_mode',\n",
    "                                 'is_downbeat']][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-failure",
   "metadata": {},
   "source": [
    "[//]:![example_extended_note_array_cof.png](https://raw.githubusercontent.com/CPJKU/partitura_tutorial/main/static/example_extended_note_array_cof.png)\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/CPJKU/partitura_tutorial/main/static/example_extended_note_array_cof.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f1bea",
   "metadata": {},
   "source": [
    "#### Extending note arrays with partitura.musicanalysis.note_features\n",
    "\n",
    "Note arrays can further be extended with note features. Note features are musical attributes that can be retrieved by built-in helper functions. See a list of avaliable note feature functions by calling `partitura.musicanalysis.list_note_feats_functions`. Pass a list of chosen note features to `partitura.compute_note_array` to compute an extended note array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7efe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.musicanalysis.list_note_feats_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.compute_note_array(score, feature_functions=[\n",
    " 'metrical_feature',\n",
    " 'metrical_strength_feature'\n",
    "                      ])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-elite",
   "metadata": {},
   "source": [
    "#### 4.1.3. Creating a custom note array from scratch from a `Part` object\n",
    "\n",
    "Sometimes we are interested in other note-level information that is not included in the standard note features. \n",
    "With partitura we can create such a custom note array easily!\n",
    "\n",
    "For example, imagine that we want a note array that includes whether the notes have an accent mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-rhythm",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path to the MusicXML file\n",
    "score_fn = os.path.join(MUSICXML_DIR, 'Chopin_op10_no3.musicxml')\n",
    "\n",
    "# Load the score into a `Part` object\n",
    "score_part = pt.load_musicxml(score_fn)[0]\n",
    "\n",
    "def get_accent_note_array(part):\n",
    "    \n",
    "    fields = [(\"onset_beat\", \"f4\"), \n",
    "              (\"pitch\", \"i4\"),\n",
    "              (\"accent\", \"i4\")]\n",
    "    # Get all notes in the part\n",
    "    notes = part.notes_tied\n",
    "    # Beat map (maps divs to score time in beats)\n",
    "    beat_map = part.beat_map\n",
    "    N = len(notes)\n",
    "    note_array = np.zeros(N, dtype=fields)\n",
    "    for i, n in enumerate(notes):\n",
    "        # MIDI pitch\n",
    "        note_array[i]['pitch'] = n.midi_pitch\n",
    "        # Get the onset time in beats\n",
    "        note_array[i]['onset_beat'] = beat_map(n.start.t)\n",
    "        \n",
    "        # Iterate over articulations in the note\n",
    "        if n.articulations:\n",
    "            for art in n.articulations:\n",
    "                if art == 'accent':\n",
    "                    note_array[i]['accent'] = 1\n",
    "    return note_array\n",
    "\n",
    "accent_note_array = get_accent_note_array(score_part)\n",
    "\n",
    "accented_note_idxs = np.where(accent_note_array['accent'])\n",
    "print(accent_note_array[accented_note_idxs][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-season",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/CPJKU/partitura_tutorial/raw/main/static/example_note_array_accents.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-fundamental",
   "metadata": {},
   "source": [
    "### 4.2 Piano rolls\n",
    "\n",
    "Piano rolls are 2D matrices that represent pitch and time information. The time represents time steps (at a given resolution), while the pitch axis represents which notes are active at a given time step. We can think of piano rolls as the symbolic equivalent of spectrograms. \n",
    "\n",
    "#### Extracting a piano roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change the example\n",
    "# Path to the MusicXML file\n",
    "score_fn = os.path.join(MUSICXML_DIR, 'Chopin_op10_no3.musicxml')\n",
    "\n",
    "# Load the score\n",
    "score = pt.load_musicxml(score_fn)\n",
    "# compute piano roll\n",
    "pianoroll = pt.utils.compute_pianoroll(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-nitrogen",
   "metadata": {},
   "source": [
    "The `compute_pianoroll` method has a few arguments to customize the resulting piano roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_range = True\n",
    "time_unit = 'beat'\n",
    "time_div = 10\n",
    "pianoroll = pt.utils.compute_pianoroll(\n",
    "    note_info=score, # a `Score`, `Performance`, `Part`, `PerformedPart` or a note array\n",
    "    time_unit=time_unit, # beat, quarter, div, sec, etc. (depending on note_info)\n",
    "    time_div=time_div, # Number of cells per time unit\n",
    "    piano_range=piano_range # Use range of the piano (88 keys)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-coast",
   "metadata": {},
   "source": [
    "An important thing to remember is that in piano rolls generated by `compute_pianoroll`, rows (the vertical axis) represent the pitch dimension and the columns (horizontal) the time dimension. \n",
    "This results in a more intuitive way of plotting the piano roll. \n",
    "For other applications the transposed version of this piano roll might be more useful (i.e., rows representing time steps and columns representing pitch information).\n",
    "\n",
    "Since piano rolls can result in very large matrices where most of the elements are 0, the output of `compute_pianoroll` is a [scipy sparse matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html). To convert it to a regular numpy array, we can simply use `pianoroll.toarray()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-answer",
   "metadata": {},
   "source": [
    "Let's plot the piano roll!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(pianoroll.toarray(), origin=\"lower\", cmap='gray', interpolation='nearest', aspect='auto')\n",
    "ax.set_xlabel(f'Time ({time_unit}s/{time_div})')\n",
    "ax.set_ylabel('Piano key' if piano_range else 'MIDI pitch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-tract",
   "metadata": {},
   "source": [
    "In some cases, we want to know the \"coordinates\" of each of the notes in the piano roll. The `compute_pianoroll` method includes an option to return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-owner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pianoroll, note_indices = pt.utils.compute_pianoroll(score_part, return_idxs=True)\n",
    "\n",
    "# MIDI pitch, start, end\n",
    "print(note_indices[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-denial",
   "metadata": {},
   "source": [
    "#### Generating a note array from a piano roll\n",
    "\n",
    "Partitura also includes a method to generate a note array from a piano roll, which can be used to generate a MIDI file. \n",
    "This method would be useful, e.g., for music generation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "pianoroll = pt.utils.compute_pianoroll(score_part)\n",
    "\n",
    "new_note_array = pt.utils.pianoroll_to_notearray(pianoroll)\n",
    "\n",
    "# We can export the note array to a MIDI file\n",
    "ppart = pt.performance.PerformedPart.from_note_array(new_note_array)\n",
    "\n",
    "# pt.save_performance_midi(ppart, \"newmidi.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372b392",
   "metadata": {},
   "source": [
    "## 5. Music Analysis\n",
    "\n",
    "Automatic music analysis is one of the main areas where partitura pipelines are useful. Furthermore, for comparison and non-state-of-the-art applications partitura also provides baseline algorithms for several music analysis tasks:\n",
    "\n",
    "|Returns| Method|Notes|\n",
    "|:---|:---|:---|\n",
    "|Voices | `partitura.musicanalysis.estimate_voices`| Estimate each note's voice |\n",
    "|Key | `partitura.musicanalysis.estimate_key`| |\n",
    "|Pitch Spelling |  `partitura.musicanalysis.estimate_spelling`| Infer correct pitch spelling from MIDI pitches|\n",
    "|Tonal Tension|  `partitura.musicanalysis.estimate_tonaltension`||\n",
    "|Meter, Beats, Tempo|  `partitura.musicanalysis.estimate_time`||\n",
    "\n",
    "\n",
    "\n",
    "## The end of the tutorial, the start of your yet untold adventures in symbolic music processing...\n",
    "\n",
    "Thank you for trying out partitura! We hope it serves you well. \n",
    "\n",
    "If you miss a particular functionality or encounter a bug, we appreciate it if you raise an issue on github: https://github.com/CPJKU/partitura/issues"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNCzhR7KnjsrjKGf/HDyInO",
   "include_colab_link": true,
   "name": "Partitura tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "172a5ce276eb1d0d801a9beadd7c9d3aac7210a29cee87eb8cc563f5ca08be0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}