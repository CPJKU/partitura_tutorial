{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2085cc7a",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/CPJKU/partitura_tutorial/blob/main/notebooks/04_generation/Drum_Generation_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db255b2a",
   "metadata": {},
   "source": [
    "# Drum Generation Transformer\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "### Install packages\n",
    "\n",
    "Welcome to this partitura tutorial notebook! If you run it locally, we assume you cloned the full tutorial repository from https://github.com/CPJKU/partitura_tutorial.git and have partitura installed.\n",
    "\n",
    "Partitura is available in github https://github.com/CPJKU/partitura\n",
    "You can install it with `pip install partitura`.\n",
    "\n",
    "If any other imports fail, please install them in your local environment.\n",
    "\n",
    "If you run it in colab, partitura will be installed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dea15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install partitura\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011a3c8",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df7e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, ConcatDataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import os\n",
    "if not IN_COLAB:\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import partitura as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a21c7d",
   "metadata": {},
   "source": [
    "### External files\n",
    "\n",
    "If run locally, external scripts are loaded directly from the cloned tutorial repository.\n",
    "\n",
    "If run in colab, external scripts are imported by httpimport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c572d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # point to the raw script\n",
    "    passurl = \"https://raw.githubusercontent.com/CPJKU/partitura_tutorial/main/notebooks/04_generation/generation_helpers.py\"\n",
    "    # passurl = \"https://gist.githubusercontent.com/operatorequals/ee5049677e7bbc97af2941d1d3f04ace/raw/e55fa867d3fb350f70b2897bb415f410027dd7e4\"\n",
    "    # with httpimport.remote_repo([\"hello\"], passurl):\n",
    "    #     import (\n",
    "    #     INV_PITCH_DICT_SIMPLE,\n",
    "    #     tokens_2_notearray,\n",
    "    #     save_notearray_2_midifile,\n",
    "    #     generate_tokenized_data,\n",
    "    #     batch_data,\n",
    "    #     PositionalEncoding,\n",
    "    #     Transformer,\n",
    "    #     sample_from_logits,\n",
    "    #     sample_loop\n",
    "    # )\n",
    "else:\n",
    "    from generation_helpers import (\n",
    "        INV_PITCH_DICT_SIMPLE,\n",
    "        tokens_2_notearray,\n",
    "        save_notearray_2_midifile,\n",
    "        generate_tokenized_data,\n",
    "        batch_data,\n",
    "        PositionalEncoding,\n",
    "        Transformer,\n",
    "        sample_from_logits,\n",
    "        sample_loop\n",
    "    )\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c723d9",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    " \n",
    "We load all midi files in 4-4 from the dataset using partitura. If you want to load a precomputed and preprocessed dataset you can skip the next cells until the last cell before section 4 where it is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bd6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./groove-v1.0.0-midionly\"\n",
    "typ_44 = [os.path.basename(f) for f  in list(\n",
    "    glob.glob(directory + r\"\\groove\\*\\*\\*.mid\")) \n",
    "          if \"4-4\" in f]\n",
    "\n",
    "beat_type = [g.split(\"_\")[-2] for g  in typ_44]\n",
    "tempo = [int(g.split(\"_\")[-3]) for g  in typ_44]\n",
    "vals, counts = np.unique(tempo, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a956c0d",
   "metadata": {},
   "source": [
    "### Histogram of tempos marked in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f5e9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0.        , 0.01666667, 0.03333333, 0.05      , 0.06666667,\n        0.08333333, 0.1       , 0.11666667, 0.13333333, 0.15      ,\n        0.16666667, 0.18333333, 0.2       , 0.21666667, 0.23333333,\n        0.25      , 0.26666667, 0.28333333, 0.3       , 0.31666667,\n        0.33333333, 0.35      , 0.36666667, 0.38333333, 0.4       ,\n        0.41666667, 0.43333333, 0.45      , 0.46666667, 0.48333333,\n        0.5       , 0.51666667, 0.53333333, 0.55      , 0.56666667,\n        0.58333333, 0.6       , 0.61666667, 0.63333333, 0.65      ,\n        0.66666667, 0.68333333, 0.7       , 0.71666667, 0.73333333,\n        0.75      , 0.76666667, 0.78333333, 0.8       , 0.81666667,\n        0.83333333, 0.85      , 0.86666667, 0.88333333, 0.9       ,\n        0.91666667, 0.93333333, 0.95      , 0.96666667, 0.98333333,\n        1.        ]),\n <BarContainer object of 60 artists>)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfaUlEQVR4nO3de3DU1f3/8VcuZIPKJnLLElxEKAoKypiYENShlUxjYdSMOCJSQJpKrUAtoSg3Sest1isqKIOtpY5QKFYZxUwsBu9EwARauVYLAkI3QJEsgiQhOb8/HNZfSghJvuyGffN8zHzG4bPn7J7PEd2nH3ZjjHPOCQAAwIjY1l4AAADA6UTcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwJT41l5Aa6irq9OePXvUrl07xcTEtPZyAABAEzjndOjQIaWmpio29uT3Z87KuNmzZ4/8fn9rLwMAALTArl27dMEFF5z08bMybtq1ayfpu83xer2tvBoAANAUwWBQfr8/9D5+Mmdl3Bz/oyiv10vcAAAQZU71kRI+UAwAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMCUicTN37lx1795diYmJyszM1Jo1axodv3TpUvXu3VuJiYnq16+fioqKTjr2rrvuUkxMjGbPnn2aVw0AAKJR2ONmyZIlys/PV0FBgcrLy3XFFVcoJydHe/fubXD8qlWrNGLECOXl5WndunXKzc1Vbm6uNmzYcMLY119/XZ988olSU1PDfRkAACBKhD1unnrqKd15550aO3asLr30Us2bN0/nnHOOXnrppQbHP/PMM7r++us1ZcoU9enTRw8++KCuvPJKzZkzp9643bt3a+LEiVq4cKHatGkT7ssAAABRIqxxU11drbKyMmVnZ3//grGxys7OVmlpaYNzSktL642XpJycnHrj6+rqNGrUKE2ZMkWXXXbZKddRVVWlYDBY7wAAADaFNW7279+v2tpapaSk1DufkpKiQCDQ4JxAIHDK8b///e8VHx+vX/3qV01aR2FhoZKSkkKH3+9v5pUAAIBoEXXfliorK9MzzzyjBQsWKCYmpklzpk2bpsrKytCxa9euMK8SAAC0lrDGTceOHRUXF6eKiop65ysqKuTz+Rqc4/P5Gh3/4Ycfau/everWrZvi4+MVHx+vHTt2aPLkyerevXuDz+nxeOT1eusdAADAprDGTUJCgtLS0lRSUhI6V1dXp5KSEmVlZTU4Jysrq954SVqxYkVo/KhRo/TPf/5T69evDx2pqamaMmWK3n777fBdDAAAiArx4X6B/Px8jRkzRunp6crIyNDs2bN1+PBhjR07VpI0evRode3aVYWFhZKke+65R4MGDdKTTz6poUOHavHixfr00081f/58SVKHDh3UoUOHeq/Rpk0b+Xw+XXLJJeG+HAAAcIYLe9wMHz5c+/bt06xZsxQIBNS/f38VFxeHPjS8c+dOxcZ+fwNp4MCBWrRokWbOnKnp06erV69eWrZsmfr27RvupQIAAANinHOutRcRacFgUElJSaqsrOTzNwAARImmvn9H3belAAAAGkPcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwJSIxM3cuXPVvXt3JSYmKjMzU2vWrGl0/NKlS9W7d28lJiaqX79+KioqCj1WU1Oj++67T/369dO5556r1NRUjR49Wnv27An3ZQAAgCgQ9rhZsmSJ8vPzVVBQoPLycl1xxRXKycnR3r17Gxy/atUqjRgxQnl5eVq3bp1yc3OVm5urDRs2SJKOHDmi8vJy3X///SovL9drr72mrVu36sYbbwz3pQAAgCgQ45xz4XyBzMxMXXXVVZozZ44kqa6uTn6/XxMnTtTUqVNPGD98+HAdPnxYy5cvD50bMGCA+vfvr3nz5jX4GmvXrlVGRoZ27Nihbt26nXJNwWBQSUlJqqyslNfrbeGVAQCASGrq+3dY79xUV1errKxM2dnZ379gbKyys7NVWlra4JzS0tJ64yUpJyfnpOMlqbKyUjExMUpOTm7w8aqqKgWDwXoHAACwKaxxs3//ftXW1iolJaXe+ZSUFAUCgQbnBAKBZo0/evSo7rvvPo0YMeKkFVdYWKikpKTQ4ff7W3A1AAAgGkT1t6Vqamp06623yjmnF1544aTjpk2bpsrKytCxa9euCK4SAABEUnw4n7xjx46Ki4tTRUVFvfMVFRXy+XwNzvH5fE0afzxsduzYoZUrVzb6Z28ej0cej6eFVwEAAKJJWO/cJCQkKC0tTSUlJaFzdXV1KikpUVZWVoNzsrKy6o2XpBUrVtQbfzxsPv/8c73zzjvq0KFDeC4AAABEnbDeuZGk/Px8jRkzRunp6crIyNDs2bN1+PBhjR07VpI0evRode3aVYWFhZKke+65R4MGDdKTTz6poUOHavHixfr00081f/58Sd+FzS233KLy8nItX75ctbW1oc/jtG/fXgkJCeG+JAAAcAYLe9wMHz5c+/bt06xZsxQIBNS/f38VFxeHPjS8c+dOxcZ+fwNp4MCBWrRokWbOnKnp06erV69eWrZsmfr27StJ2r17t9544w1JUv/+/eu91rvvvqsf/vCH4b4kAABwBgv7z7k5E/FzbgAAiD5nxM+5AQAAiDTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKZEJG7mzp2r7t27KzExUZmZmVqzZk2j45cuXarevXsrMTFR/fr1U1FRUb3HnXOaNWuWunTporZt2yo7O1uff/55OC8BAABEibDHzZIlS5Sfn6+CggKVl5friiuuUE5Ojvbu3dvg+FWrVmnEiBHKy8vTunXrlJubq9zcXG3YsCE05rHHHtOzzz6refPmafXq1Tr33HOVk5Ojo0ePhvtyAADAGS7GOefC+QKZmZm66qqrNGfOHElSXV2d/H6/Jk6cqKlTp54wfvjw4Tp8+LCWL18eOjdgwAD1799f8+bNk3NOqampmjx5sn7zm99IkiorK5WSkqIFCxbotttuO+WagsGgkpKSVFlZKa/Xe5quFAAAhFNT37/DeuemurpaZWVlys7O/v4FY2OVnZ2t0tLSBueUlpbWGy9JOTk5ofHbt29XIBCoNyYpKUmZmZknfc6qqioFg8F6BwAAsCmscbN//37V1tYqJSWl3vmUlBQFAoEG5wQCgUbHH/9rc56zsLBQSUlJocPv97foegAAwJnvrPi21LRp01RZWRk6du3a1dpLAgAAYRLWuOnYsaPi4uJUUVFR73xFRYV8Pl+Dc3w+X6Pjj/+1Oc/p8Xjk9XrrHQAAwKawxk1CQoLS0tJUUlISOldXV6eSkhJlZWU1OCcrK6veeElasWJFaPxFF10kn89Xb0wwGNTq1atP+pwAAODsER/uF8jPz9eYMWOUnp6ujIwMzZ49W4cPH9bYsWMlSaNHj1bXrl1VWFgoSbrnnns0aNAgPfnkkxo6dKgWL16sTz/9VPPnz5ckxcTE6Ne//rUeeugh9erVSxdddJHuv/9+paamKjc3N9yXAwAAznBhj5vhw4dr3759mjVrlgKBgPr376/i4uLQB4J37typ2NjvbyANHDhQixYt0syZMzV9+nT16tVLy5YtU9++fUNj7r33Xh0+fFjjxo3TwYMHdc0116i4uFiJiYnhvhwAAHCGC/vPuTkT8XNuAACIPmfEz7kBAACINOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAApoQtbg4cOKCRI0fK6/UqOTlZeXl5+uabbxqdc/ToUY0fP14dOnTQeeedp2HDhqmioiL0+D/+8Q+NGDFCfr9fbdu2VZ8+ffTMM8+E6xIAAEAUClvcjBw5Uhs3btSKFSu0fPlyffDBBxo3blyjcyZNmqQ333xTS5cu1fvvv689e/bo5ptvDj1eVlamzp0765VXXtHGjRs1Y8YMTZs2TXPmzAnXZQAAgCgT45xzp/tJN2/erEsvvVRr165Venq6JKm4uFhDhgzRV199pdTU1BPmVFZWqlOnTlq0aJFuueUWSdKWLVvUp08flZaWasCAAQ2+1vjx47V582atXLmyyesLBoNKSkpSZWWlvF5vC64QAABEWlPfv8Ny56a0tFTJycmhsJGk7OxsxcbGavXq1Q3OKSsrU01NjbKzs0PnevfurW7duqm0tPSkr1VZWan27dufvsUDAICoFh+OJw0EAurcuXP9F4qPV/v27RUIBE46JyEhQcnJyfXOp6SknHTOqlWrtGTJEr311luNrqeqqkpVVVWhXweDwSZcBQAAiEbNunMzdepUxcTENHps2bIlXGutZ8OGDbrppptUUFCgH//4x42OLSwsVFJSUujw+/0RWSMAAIi8Zt25mTx5su64445Gx/To0UM+n0979+6td/7YsWM6cOCAfD5fg/N8Pp+qq6t18ODBendvKioqTpizadMmDR48WOPGjdPMmTNPue5p06YpPz8/9OtgMEjgAABgVLPiplOnTurUqdMpx2VlZengwYMqKytTWlqaJGnlypWqq6tTZmZmg3PS0tLUpk0blZSUaNiwYZKkrVu3aufOncrKygqN27hxo6677jqNGTNGDz/8cJPW7fF45PF4mjQWAABEt7B8W0qSfvKTn6iiokLz5s1TTU2Nxo4dq/T0dC1atEiStHv3bg0ePFgvv/yyMjIyJEm//OUvVVRUpAULFsjr9WrixImSvvtsjfTdH0Vdd911ysnJ0eOPPx56rbi4uCZF13F8WwoAgOjT1PfvsHygWJIWLlyoCRMmaPDgwYqNjdWwYcP07LPPhh6vqanR1q1bdeTIkdC5p59+OjS2qqpKOTk5ev7550OPv/rqq9q3b59eeeUVvfLKK6HzF154ob788stwXQoAAIgiYbtzcybjzg0AANGnVX/ODQAAQGshbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwJW9wcOHBAI0eOlNfrVXJysvLy8vTNN980Oufo0aMaP368OnTooPPOO0/Dhg1TRUVFg2P/+9//6oILLlBMTIwOHjwYhisAAADRKGxxM3LkSG3cuFErVqzQ8uXL9cEHH2jcuHGNzpk0aZLefPNNLV26VO+//7727Nmjm2++ucGxeXl5uvzyy8OxdAAAEMVinHPudD/p5s2bdemll2rt2rVKT0+XJBUXF2vIkCH66quvlJqaesKcyspKderUSYsWLdItt9wiSdqyZYv69Omj0tJSDRgwIDT2hRde0JIlSzRr1iwNHjxYX3/9tZKTk5u8vmAwqKSkJFVWVsrr9f7fLhYAAEREU9+/w3LnprS0VMnJyaGwkaTs7GzFxsZq9erVDc4pKytTTU2NsrOzQ+d69+6tbt26qbS0NHRu06ZNeuCBB/Tyyy8rNrZpy6+qqlIwGKx3AAAAm8ISN4FAQJ07d653Lj4+Xu3bt1cgEDjpnISEhBPuwKSkpITmVFVVacSIEXr88cfVrVu3Jq+nsLBQSUlJocPv9zfvggAAQNRoVtxMnTpVMTExjR5btmwJ11o1bdo09enTRz/96U+bPa+ysjJ07Nq1K0wrBAAArS2+OYMnT56sO+64o9ExPXr0kM/n0969e+udP3bsmA4cOCCfz9fgPJ/Pp+rqah08eLDe3ZuKiorQnJUrV+qzzz7Tq6++Kkk6/nGhjh07asaMGfrd737X4HN7PB55PJ6mXCIAAIhyzYqbTp06qVOnTqccl5WVpYMHD6qsrExpaWmSvguTuro6ZWZmNjgnLS1Nbdq0UUlJiYYNGyZJ2rp1q3bu3KmsrCxJ0t/+9jd9++23oTlr167Vz372M3344Yfq2bNncy4FAAAY1ay4aao+ffro+uuv15133ql58+appqZGEyZM0G233Rb6ptTu3bs1ePBgvfzyy8rIyFBSUpLy8vKUn5+v9u3by+v1auLEicrKygp9U+p/A2b//v2h12vOt6UAAIBdYYkbSVq4cKEmTJigwYMHKzY2VsOGDdOzzz4berympkZbt27VkSNHQueefvrp0Niqqirl5OTo+eefD9cSAQCAQWH5OTdnOn7ODQAA0adVf84NAABAayFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKfGtvYDW4JyTJAWDwVZeCQAAaKrj79vH38dP5qyMm0OHDkmS/H5/K68EAAA016FDh5SUlHTSx2PcqfLHoLq6Ou3Zs0ft2rVTTEzMaX3uYDAov9+vXbt2yev1ntbnxvfY58hgnyODfY4M9jkywrnPzjkdOnRIqampio09+Sdrzso7N7GxsbrgggvC+hper5d/eCKAfY4M9jky2OfIYJ8jI1z73Ngdm+P4QDEAADCFuAEAAKYQN6eZx+NRQUGBPB5Pay/FNPY5MtjnyGCfI4N9jowzYZ/Pyg8UAwAAu7hzAwAATCFuAACAKcQNAAAwhbgBAACmEDfNNHfuXHXv3l2JiYnKzMzUmjVrGh2/dOlS9e7dW4mJierXr5+KiooitNLo15y9fvHFF3Xttdfq/PPP1/nnn6/s7OxT/r3Bd5r7e/q4xYsXKyYmRrm5ueFdoBHN3eeDBw9q/Pjx6tKlizwejy6++GL+/dEEzd3n2bNn65JLLlHbtm3l9/s1adIkHT16NEKrjU4ffPCBbrjhBqWmpiomJkbLli075Zz33ntPV155pTwej37wgx9owYIF4V2kQ5MtXrzYJSQkuJdeeslt3LjR3XnnnS45OdlVVFQ0OP7jjz92cXFx7rHHHnObNm1yM2fOdG3atHGfffZZhFcefZq717fffrubO3euW7dundu8ebO74447XFJSkvvqq68ivPLo0tx9Pm779u2ua9eu7tprr3U33XRTZBYbxZq7z1VVVS49Pd0NGTLEffTRR2779u3uvffec+vXr4/wyqNLc/d54cKFzuPxuIULF7rt27e7t99+23Xp0sVNmjQpwiuPLkVFRW7GjBnutddec5Lc66+/3uj4bdu2uXPOOcfl5+e7TZs2ueeee87FxcW54uLisK2RuGmGjIwMN378+NCva2trXWpqqissLGxw/K233uqGDh1a71xmZqb7xS9+EdZ1WtDcvf5fx44dc+3atXN//vOfw7VEE1qyz8eOHXMDBw50f/jDH9yYMWOImyZo7j6/8MILrkePHq66ujpSSzShufs8fvx4d91119U7l5+f766++uqwrtOSpsTNvffe6y677LJ654YPH+5ycnLCti7+WKqJqqurVVZWpuzs7NC52NhYZWdnq7S0tME5paWl9cZLUk5OzknH4zst2ev/deTIEdXU1Kh9+/bhWmbUa+k+P/DAA+rcubPy8vIiscyo15J9fuONN5SVlaXx48crJSVFffv21SOPPKLa2tpILTvqtGSfBw4cqLKystAfXW3btk1FRUUaMmRIRNZ8tmiN98Kz8n+c2RL79+9XbW2tUlJS6p1PSUnRli1bGpwTCAQaHB8IBMK2Tgtastf/67777lNqauoJ/0Dhey3Z548++kh//OMftX79+gis0IaW7PO2bdu0cuVKjRw5UkVFRfriiy909913q6amRgUFBZFYdtRpyT7ffvvt2r9/v6655ho553Ts2DHdddddmj59eiSWfNY42XthMBjUt99+q7Zt25721+TODcx59NFHtXjxYr3++utKTExs7eWYcejQIY0aNUovvviiOnbs2NrLMa2urk6dO3fW/PnzlZaWpuHDh2vGjBmaN29eay/NlPfee0+PPPKInn/+eZWXl+u1117TW2+9pQcffLC1l4b/I+7cNFHHjh0VFxenioqKeucrKirk8/kanOPz+Zo1Ht9pyV4f98QTT+jRRx/VO++8o8svvzycy4x6zd3nf//73/ryyy91ww03hM7V1dVJkuLj47V161b17NkzvIuOQi35/dylSxe1adNGcXFxoXN9+vRRIBBQdXW1EhISwrrmaNSSfb7//vs1atQo/fznP5ck9evXT4cPH9a4ceM0Y8YMxcby3/+nw8neC71eb1ju2kjcuWmyhIQEpaWlqaSkJHSurq5OJSUlysrKanBOVlZWvfGStGLFipOOx3dasteS9Nhjj+nBBx9UcXGx0tPTI7HUqNbcfe7du7c+++wzrV+/PnTceOON+tGPfqT169fL7/dHcvlRoyW/n6+++mp98cUXoXiUpH/961/q0qULYXMSLdnnI0eOnBAwx4PS8b9dPG1a5b0wbB9VNmjx4sXO4/G4BQsWuE2bNrlx48a55ORkFwgEnHPOjRo1yk2dOjU0/uOPP3bx8fHuiSeecJs3b3YFBQV8FbyJmrvXjz76qEtISHCvvvqq+89//hM6Dh061FqXEBWau8//i29LNU1z93nnzp2uXbt2bsKECW7r1q1u+fLlrnPnzu6hhx5qrUuICs3d54KCAteuXTv3l7/8xW3bts39/e9/dz179nS33npra11CVDh06JBbt26dW7dunZPknnrqKbdu3Tq3Y8cO55xzU6dOdaNGjQqNP/5V8ClTprjNmze7uXPn8lXwM81zzz3nunXr5hISElxGRob75JNPQo8NGjTIjRkzpt74v/71r+7iiy92CQkJ7rLLLnNvvfVWhFccvZqz1xdeeKGTdMJRUFAQ+YVHmeb+nv7/ETdN19x9XrVqlcvMzHQej8f16NHDPfzww+7YsWMRXnX0ac4+19TUuN/+9reuZ8+eLjEx0fn9fnf33Xe7r7/+OvILjyLvvvtug/++Pb63Y8aMcYMGDTphTv/+/V1CQoLr0aOH+9Of/hTWNcY4x703AABgB5+5AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABT/h8EumuoKAthtAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vals, counts, c = \"r\")\n",
    "plt.hist(np.array(tempo), bins= 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab07ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "      directory = \"./groove-v1.0.0-midionly\",\n",
    "      min_seq_length=10, \n",
    "      time_sig=\"4-4\", \n",
    "      beat_type = None\n",
    "              ):\n",
    "    \"\"\"\n",
    "    loads groove dataset data from directory\n",
    "    into a list of dictionaries containing the\n",
    "    note array as well as note sequence metadata.\n",
    "    \n",
    "    Args:\n",
    "        directory: dir of the dataset\n",
    "        min_seq_length: minimal sequence length, a\n",
    "            all shorter performances are discarded\n",
    "        time_sig: only performances of this time sig\n",
    "            are loaded\n",
    "        beat_type: type of beat to load (\"beat\", \n",
    "            \"fill\", or None = both)\n",
    "        \n",
    "    Returns:\n",
    "        a list of dicts containing note arrays.\n",
    "        \n",
    "    \"\"\"\n",
    "    # load data\n",
    "    files = glob.glob(directory + r\"\\groove\\*\\*\\*.mid\")\n",
    "    files.sort()\n",
    "    sequences = []\n",
    "    if beat_type is None:\n",
    "        beat_types = [\"beat\", \"fill\"]\n",
    "    else:\n",
    "        beat_types = [beat_type]\n",
    "    for fn in files:\n",
    "        bn = os.path.basename(fn)\n",
    "        bns = bn.split(\"_\")\n",
    "        tempo = int(bns[-3])\n",
    "        bt = bns[-2]\n",
    "        ts = bns[-1].split('.')[-2]\n",
    "        if ts == time_sig and bt in beat_types:\n",
    "            seq = pt.load_performance_midi(fn, time_in_divs = True)[0]\n",
    "            if len(seq.notes) > min_seq_length:\n",
    "                na = seq.note_array()\n",
    "                namax = (na['onset_sec'] + na['duration_sec']).max()\n",
    "                namin = (na['onset_sec']).min()\n",
    "                dur_in_q = (namax - namin)/seq.ppq\n",
    "                seq_object = {\n",
    "                    \"id\": bn,\n",
    "                    \"na\": na,\n",
    "                    \"ppq\": seq.ppq,\n",
    "                    \"tempo\": tempo,\n",
    "                    \"beat_type\": bt,\n",
    "                    \"namax\": namax,\n",
    "                    \"namin\": namin,\n",
    "                    \"dur_in_q\": dur_in_q\n",
    "                }\n",
    "                sequences.append(seq_object)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8aa2d5",
   "metadata": {},
   "source": [
    "### Call the loading function (might take a moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2829ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = load_data(directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ac278",
   "metadata": {},
   "source": [
    "### Histogram of performance durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89db8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_in_quarters = [k[\"dur_in_q\"] for k in seqs if k[\"beat_type\"] == \"beat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35bb2f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dur_in_quarters, bins = 60)\n",
    "liq = np.array(dur_in_quarters)\n",
    "print((liq >= 4).sum(), (liq >= -4).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4994b15",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing: Segmentation & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a8d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "PITCH_DICT_SIMPLE = {\n",
    "    36:0, #Kick\n",
    "    38:1, #Snare (Head)\n",
    "    40:1, #Snare (Rim) \n",
    "    37:1, #Snare X-Stick\n",
    "    48:2, #Tom 1\n",
    "    50:2, #Tom 1 (Rim) \n",
    "    45:2, #Tom 2\n",
    "    47:2, #Tom 2 (Rim) \n",
    "    43:2, #Tom 3 \n",
    "    58:2, #Tom 3 (Rim)\n",
    "    46:3, #HH Open (Bow) \n",
    "    26:3, #HH Open (Edge) \n",
    "    42:3, #HH Closed (Bow)\n",
    "    22:3, #HH Closed (Edge)\n",
    "    44:3, #HH Pedal\n",
    "    49:4, #Crash 1\n",
    "    55:4, #Crash 1\n",
    "    57:4, #Crash 2\n",
    "    52:4, #Crash 2 \n",
    "    51:5, #Ride (Bow) \n",
    "    59:5, #Ride (Edge) \n",
    "    53:5, #Ride (Bell)\n",
    "    'default':6\n",
    "}\n",
    "\n",
    "def pitch_encoder(pitch, pitch_dict = PITCH_DICT_SIMPLE):\n",
    "    # 22 different instruments  in dataset, default 23rd class \n",
    "    a = pitch_dict['default']\n",
    "    try:\n",
    "        a = pitch_dict[pitch]\n",
    "    except:\n",
    "        print(\"unknown instrument\")\n",
    "    return a\n",
    "\n",
    "def time_encoder(time_div, ppq):\n",
    "    # base 2 encoding of time, starting at half note, ending at 128th\n",
    "    power_two_classes = list()\n",
    "    for i in range(7):\n",
    "        power_two_classes.append(int(time_div // (ppq * (2 **(1-i)))))\n",
    "        time_div = time_div % (ppq * 2 **(1-i))\n",
    "    return power_two_classes\n",
    "\n",
    "def velocity_encoder(vel):\n",
    "    # 8 classes of velocity\n",
    "    return vel // 2 ** 4\n",
    "\n",
    "def tempo_encoder(tmp):\n",
    "    # 8 classes of tempo between 60 and 180\n",
    "    return (np.clip(tmp, 60, 179) - 60) // 15\n",
    "\n",
    "def tokenizer(seq):\n",
    "    tokens = list()\n",
    "    na = seq[\"na\"]\n",
    "    fill_encoding = 0\n",
    "    if seq[\"beat_type\"] == \"fill\":\n",
    "        fill_encoding = 1\n",
    "    tempo_encoding = tempo_encoder(seq[\"tempo\"])\n",
    "\n",
    "    for note in na:\n",
    "        te = time_encoder(note[\"onset_sec\"]%(seq['ppq']*4), seq['ppq'])\n",
    "        pe = pitch_encoder(note[\"pitch\"])\n",
    "        ve = velocity_encoder(note[\"velocity\"])\n",
    "        \n",
    "        tokens.append(te + [pe, ve, tempo_encoding, fill_encoding])\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def measure_segmentation(seq, beats = 4, minimal_notes = 1):\n",
    "    mod = beats * seq['ppq']\n",
    "    no_of_measures = int(seq[\"namax\"] // mod + 1)\n",
    "    \n",
    "    segmented_seq = list()\n",
    "    for measure_idx in range(no_of_measures):\n",
    "        na = seq[\"na\"] \n",
    "        new_na = np.copy(na[na[\"onset_sec\"] // mod == measure_idx])\n",
    "        if len(new_na) >= minimal_notes:\n",
    "            new_seq = copy.copy(seq)\n",
    "            new_seq[\"na\"] = new_na\n",
    "            segmented_seq.append(new_seq)\n",
    "        else:\n",
    "            continue\n",
    "    return segmented_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6feff872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try uncommenting the next lines to see the outputs of these functions.\n",
    "# t = tokenizer(seqs[0])\n",
    "# ss = measure_segmentation(seqs[0], minimal_notes = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6bfce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90068bf0",
   "metadata": {},
   "source": [
    "### Training set generation (might take a moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f510c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batches of size 128\n"
     ]
    }
   ],
   "source": [
    "train_data = generate_tokenized_data(seqs,\n",
    "                                     measure_segmentation,\n",
    "                                     tokenizer,\n",
    "                                     minimal_notes = 20)\n",
    "train_dataloader = batch_data(train_data,\n",
    "                              batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e0074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try uncommenting the next lines to see the outputs of these functions.\n",
    "# train_dataloader[0].shape # batch, sequence, tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7824e7a",
   "metadata": {},
   "source": [
    "### Saving and loading a preprocessed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52895b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./dataset129.pyc', 'wb') as fh:\n",
    "#     pickle.dump(train_dataloader, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4201715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./dataset129.pyc', 'rb') as fh:\n",
    "#     train_dataloader = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de36f1",
   "metadata": {},
   "source": [
    "## 4. Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535b9ed",
   "metadata": {},
   "source": [
    "![MODEL](https://raw.githubusercontent.com/CPJKU/partitura_tutorial/main/static/drumtransformer.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30334b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiEmbedding(nn.Module):\n",
    "    '''A Multiembedding'''\n",
    "    # Initialization\n",
    "    def __init__(self, tokens2dims):\n",
    "        super().__init__()\n",
    "        # self.em_time0 = nn.Embedding(num_tokens, dim_model)\n",
    "        self.em_time0 = nn.Embedding(tokens2dims[0][0], tokens2dims[0][1])\n",
    "        self.em_time1 = nn.Embedding(tokens2dims[1][0], tokens2dims[1][1])\n",
    "        self.em_time2 = nn.Embedding(tokens2dims[2][0], tokens2dims[2][1])\n",
    "        self.em_time3 = nn.Embedding(tokens2dims[3][0], tokens2dims[3][1])\n",
    "        self.em_time4 = nn.Embedding(tokens2dims[4][0], tokens2dims[4][1])\n",
    "        self.em_time5 = nn.Embedding(tokens2dims[5][0], tokens2dims[5][1])\n",
    "        self.em_time6 = nn.Embedding(tokens2dims[6][0], tokens2dims[6][1])\n",
    "        self.em_pitch = nn.Embedding(tokens2dims[7][0], tokens2dims[7][1])\n",
    "        self.em_velocity = nn.Embedding(tokens2dims[8][0], tokens2dims[8][1])\n",
    "        self.em_tempo = nn.Embedding(tokens2dims[9][0], tokens2dims[9][1])\n",
    "        self.em_beat = nn.Embedding(tokens2dims[10][0], tokens2dims[10][1])\n",
    "        # self.total_dim = np.array([[2,2,2,2,2,2,2, # time encoding\n",
    "        #                  2,2,2,2]]).sum() # instrument, velocity, tempo, beat/fill\n",
    "    def forward(self, x):\n",
    "        '''Update Function and predict function of the model'''\n",
    "        \n",
    "        output = torch.cat((\n",
    "        self.em_time0(x[:,:,0]),\n",
    "        self.em_time1(x[:,:,1]),\n",
    "        self.em_time2(x[:,:,2]),\n",
    "        self.em_time3(x[:,:,3]),\n",
    "        self.em_time4(x[:,:,4]),\n",
    "        self.em_time5(x[:,:,5]),\n",
    "        self.em_time6(x[:,:,6]),\n",
    "        self.em_pitch(x[:,:,7]),\n",
    "        self.em_velocity(x[:,:,8]),\n",
    "        self.em_tempo(x[:,:,9]),\n",
    "        self.em_beat(x[:,:,10])),\n",
    "        dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba131735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bad68a5",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "533a46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader, tokens2dims):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    t2d = np.array(tokens2dims)\n",
    "    pred_dims = np.concatenate(([0],np.cumsum(t2d[:,0])))\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        y = batch\n",
    "        y = torch.tensor(y).to(device)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1,:]\n",
    "        y_expected = y[:,1:,:]\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        pred = model(y_input, tgt_mask)\n",
    "\n",
    "        # Permute pred to have batch size first again, that is batch / logits / sequence\n",
    "        pred = pred.permute(1, 2, 0)      \n",
    "        loss = 0\n",
    "        for k in range(11):\n",
    "            # batch / logits / sequence ----- batch / sequence / tokens\n",
    "            loss += loss_fn(pred[:,pred_dims[k]:pred_dims[k+1],:], y_expected[:,:,k])\n",
    "            \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a21b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, opt, loss_fn, train_dataloader, t2d, epochs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train_loss_list = []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model, opt, loss_fn, train_dataloader, t2d)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b341c",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b844bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in model:  264700\n"
     ]
    }
   ],
   "source": [
    "tokens2dims = [ \n",
    "            (4, 8),\n",
    "            (4, 8),\n",
    "            (4, 8),\n",
    "            (4, 4),\n",
    "            (4, 4),\n",
    "            (4, 4),\n",
    "            (4, 4),\n",
    "            (8, 16),\n",
    "            (10, 12),\n",
    "            (10, 12),\n",
    "            (4, 4)\n",
    "        ]\n",
    "\n",
    "model_spec = dict(\n",
    "    tokens2dims=tokens2dims,\n",
    "    num_heads=6,\n",
    "    num_decoder_layers=6,\n",
    "    dropout_p=0.1\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Transformer(\n",
    "    tokens2dims = model_spec[\"tokens2dims\"], \n",
    "    MultiEmbedding = MultiEmbedding, \n",
    "    num_heads = model_spec[\"num_heads\"], \n",
    "    num_decoder_layers = model_spec[\"num_decoder_layers\"], \n",
    "    dropout_p = model_spec[\"dropout_p\"], \n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters in model: \", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e170c",
   "metadata": {},
   "source": [
    "## 6. LOOP (only call to retrain / finetrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56a96d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nEPOCH = 1\\nPATH = \"modelname.pt\"\\nLOSS = train_loss_list[-1]\\nMODEL_SPEC = model_spec\\n\\ntorch.save({\\n            \\'epoch\\': EPOCH,\\n           \\'model_state_dict\\': model.state_dict(),\\n            \\'optimizer_state_dict\\': opt.state_dict(),\\n            \\'loss\\': LOSS,\\n            \\'model_spec\\': MODEL_SPEC,\\n            }, PATH)\\n'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "EPOCH = 1\n",
    "PATH = \"modelname.pt\"\n",
    "LOSS = train_loss_list[-1]\n",
    "MODEL_SPEC = model_spec\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "           'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            'model_spec': MODEL_SPEC,\n",
    "            }, PATH)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "028cdce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [24], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m PATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDrum_Transformer_Checkpoint.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPATH\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_state_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      5\u001B[0m opt\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer_state_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/torch/serialization.py:789\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    787\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    788\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m--> 789\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights_only:\n\u001B[1;32m    791\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/torch/serialization.py:1131\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1129\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1130\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m-> 1131\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1133\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m   1135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/torch/serialization.py:1101\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m loaded_storages:\n\u001B[1;32m   1100\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[0;32m-> 1101\u001B[0m     \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loaded_storages[key]\n",
      "File \u001B[0;32m~/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/torch/serialization.py:1083\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(dtype, numel, key, location)\u001B[0m\n\u001B[1;32m   1079\u001B[0m storage \u001B[38;5;241m=\u001B[39m zip_file\u001B[38;5;241m.\u001B[39mget_storage_from_record(name, numel, torch\u001B[38;5;241m.\u001B[39mUntypedStorage)\u001B[38;5;241m.\u001B[39mstorage()\u001B[38;5;241m.\u001B[39muntyped()\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[1;32m   1082\u001B[0m loaded_storages[key] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[0;32m-> 1083\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39m\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1084\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[0;32m~/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/torch/serialization.py:215\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[0;32m--> 215\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/torch/serialization.py:182\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_deserialize\u001B[39m(obj, location):\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 182\u001B[0m         device \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_cuda_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_load_uninitialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    184\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice(device):\n",
      "File \u001B[0;32m~/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/torch/serialization.py:166\u001B[0m, in \u001B[0;36mvalidate_cuda_device\u001B[0;34m(location)\u001B[0m\n\u001B[1;32m    163\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_get_device_index(location, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m--> 166\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a CUDA \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    167\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice but torch.cuda.is_available() is False. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    168\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    169\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    170\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    171\u001B[0m device_count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "PATH = \"Drum_Transformer_Checkpoint.pt\"\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82d54647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_loss_list \u001B[38;5;241m=\u001B[39m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokens2dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [21], line 10\u001B[0m, in \u001B[0;36mfit\u001B[0;34m(model, opt, loss_fn, train_dataloader, t2d, epochs)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m25\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m25\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt2d\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     train_loss_list \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [train_loss]\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn [20], line 37\u001B[0m, in \u001B[0;36mtrain_loop\u001B[0;34m(model, opt, loss_fn, dataloader, tokens2dims)\u001B[0m\n\u001B[1;32m     33\u001B[0m     opt\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     35\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtotal_loss\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "source": [
    "train_loss_list = fit(model, opt, loss_fn, train_dataloader, tokens2dims, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817677b",
   "metadata": {},
   "source": [
    "## 7. SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad410c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_loop(model, tokens2dims, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.cpu().numpy()[0,1:,:], \n",
    "                  columns=['Time Half Note', \n",
    "                           'Time Quarter Note',\n",
    "                           'Time 8th Note',\n",
    "                           'Time 16th Note',\n",
    "                           'Time 32nd Note',\n",
    "                           'Time 64th Note',\n",
    "                           'Time 128th Note',\n",
    "                           'Pitch / Instrument',\n",
    "                           'Velocity',\n",
    "                           'Tempo',\n",
    "                           'Beat type'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(16):\n",
    "    XX = X.cpu().numpy()[k,1:,:]\n",
    "    na = tokens_2_notearray(XX)\n",
    "    save_notearray_2_midifile(na, k, fn = \"PartituraTutorialBeats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b095b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc209ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7727a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "172a5ce276eb1d0d801a9beadd7c9d3aac7210a29cee87eb8cc563f5ca08be0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
