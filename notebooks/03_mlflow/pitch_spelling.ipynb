{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import partitura as pt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pitch Spelling with Partitura\n",
    "\n",
    "Have you always been bad at spelling bee, do you find that spelling notes makes this even worse. Your time of struggling is over.... Today we going to teach a Model to learn how to *pitch* spell.\n",
    "\n",
    "### Definition\n",
    "\n",
    "Spelling a pitch relates to the system of naming notes by letters (A-G) and sharp(#) and flat (♭) signs - and sometimes double sharp and flat signs, resulting in names or 'spellings' like 'A♭', 'D#', 'F♭♭'.\n",
    "\n",
    "Translating between frequencies in Hz and such names is non-trivial. You need to consider :\n",
    "\n",
    "-  The 'concert pitch' you are taking as a reference\n",
    "- The temperament in which the piece is played\n",
    "- The overall key that the music would be notated in\n",
    "- Use of the correct enharmonic equivalents for accidentals (Using the correct enharmonic equivalent, Purpose of double-sharps and double-flats?)\n",
    "\n",
    "If translating between, say, MIDI note numbers and 'spelled' names, the first two steps can be skipped.\n",
    "\n",
    "Spelled pitch names often have an octave number appended for disambiguation - e.g. 'A♭3', 'D#5'.\n",
    "\n",
    "\n",
    "### Some Spelling algorithms\n",
    "\n",
    "Partitura contains an implementation for a standard algorithm for Pitch Spelling. The algorithm in question is called ps13 created by Meredith and al.:\n",
    "\n",
    "\tThe ps13 pitch spelling algorithm, D Meredith - Journal of New Music Research, 2006\n",
    "\n",
    "Some notable algorithms and currect SOTA is PKSpell.\n",
    "\n",
    "\tPKSpell: Data-driven pitch spelling and key signature estimation\n",
    "\tF Foscarin, N Audebert, R Fournier-S'Niehotta, 2021\n",
    "\n",
    "\n",
    "Let's first download a pitch spelling dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-04 11:49:35--  https://github.com/CPJKU/vienna4x22/archive/refs/heads/master.zip\r\n",
      "Resolving github.com (github.com)... 140.82.121.4\r\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://codeload.github.com/CPJKU/vienna4x22/zip/refs/heads/master [following]\r\n",
      "--2022-11-04 11:49:39--  https://codeload.github.com/CPJKU/vienna4x22/zip/refs/heads/master\r\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.121.10\r\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.121.10|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/zip]\r\n",
      "Saving to: ‘master.zip.1’\r\n",
      "\r\n",
      "master.zip.1            [    <=>             ] 857.87K  1.02MB/s               ^C\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/CPJKU/asap-dataset/archive/refs/heads/note_alignments.zip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open ./master.zip, ./master.zip.zip or ./master.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./content\n",
    "!unzip ./master.zip -d ./content/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "files = [(os.path.join(root, file), os.path.join(os.path.dirname(root), \"musicxml\", file[:-10]+\".musicxml\")) for root, dirs, files in os.walk(\"vienna4x22-master\") for file in files if file.endswith(\".match\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "asap_files = [[(os.path.join(root, file), os.path.join(os.path.dirname(root), os.path.basename(root).split(\"_\")[0]+\".mid\"), os.path.join(os.path.dirname(root), \"xml_score.musicxml\"), os.path.join(root, os.path.splitext(file)[0]+\".match\")) for root, dirs, files in os.walk(\"vienna4x22-master\") for file in files if file.endswith(\"note_alignments.tsv\")]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "('vienna4x22-master/match/Chopin_op10_no3_p14.match',\n 'vienna4x22-master/musicxml/Chopin_op10_no3.musicxml')"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def produce_match(alignment_fn, mfn, sfn, match_name):\n",
    "\t\"\"\"\n",
    "\tProduce and Save Match.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tmfn : str\n",
    "\t\tPerformance Midi File Path\n",
    "\tsfn : str\n",
    "\t\tScore musicxml File Path\n",
    "\talignment_fn : str\n",
    "\t\tAlignment \".txt\" file path\n",
    "\tmatch_name : str\n",
    "\t\tPath and Save Name.\n",
    "\t\"\"\"\n",
    "\tdata = pd.read_csv(alignment_fn, sep=\"\\t\")\n",
    "\n",
    "\talignment = list()\n",
    "\tfor x in data[[\"xml_id\", \"midi_id\"]].to_numpy():\n",
    "\t\tif x[1] == \"deletion\":\n",
    "\t\t\tdd = dict(label=\"deletion\", score_id=x[0])\n",
    "\t\t# TODO for asap alignments to contain \"n\"\n",
    "\t\telif x[0] == \"insertion\":\n",
    "\t\t\tdd = dict(label=\"insertion\", performance_id=str(x[1]))\n",
    "\t\telse:\n",
    "\t\t\tdd = dict(label=\"match\", score_id=x[0], performance_id=str(x[1]))\n",
    "\t\talignment.append(dd)\n",
    "\tppart = pt.load_performance_midi(mfn)\n",
    "\t# This may cause re-indexing.\n",
    "\tspart = pt.score.merge_parts(pt.load_musicxml(sfn))\n",
    "\tspart = pt.score.unfold_part_maximal(spart, ignore_leaps=False)\n",
    "\tpt.save_match(alignment, ppart, spart, match_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def tokenize_pitch_spelling(ps_note):\n",
    "\t# step = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3, \"E\": 4, \"F\": 5, \"G\": 6}[]\n",
    "\talter = {0:\"\", 1:\"#\", 2:\"##\", -1:\"-\", -2:\"--\"}[ps_note[\"alter\"].item()]\n",
    "\treturn pitch_to_ix[ps_note[\"step\"].item()+alter]\n",
    "\n",
    "def create_data(files):\n",
    "\tX_train = list()\n",
    "\ty_train = list()\n",
    "\tX_test = list()\n",
    "\ty_test = list()\n",
    "\tfor match_file, score_file in files:\n",
    "\t\tperformance, alignment = pt.load_match(match_file)\n",
    "\t\tscore = pt.load_score(score_file)\n",
    "\t\tmatched_notes = [alignment[idx] for idx, d in enumerate(alignment) if d[\"label\"] == \"match\"]\n",
    "\t\tpna = performance.note_array()\n",
    "\t\tsna = score.note_array(include_pitch_spelling=True)\n",
    "\t\tX, y = np.zeros((len(matched_notes), 3), dtype=float), np.zeros((len(matched_notes), ), dtype=int)\n",
    "\t\tfor idx, match_note in enumerate(matched_notes):\n",
    "\t\t\tX[idx] = np.lib.recfunctions.structured_to_unstructured(pna[np.where(pna[\"id\"] == str(match_note[\"performance_id\"]))][[\"onset_sec\", \"duration_sec\", \"pitch\"]])\n",
    "\t\t\ty[idx] = tokenize_pitch_spelling(sna[np.where(sna[\"id\"] == match_note[\"score_id\"])][[\"step\", \"alter\", \"octave\"]])\n",
    "\t\tif os.path.basename(match_file).startswith(\"Mozart\"):\n",
    "\t\t\tX_test.append(X)\n",
    "\t\t\ty_test.append(y)\n",
    "\t\telse:\n",
    "\t\t\tX_train.append(X)\n",
    "\t\t\ty_train.append(y)\n",
    "\treturn X_train, y_train, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/io/importmusicxml.py:1338: UserWarning: Dropping slur 3 starting at 2592 (n120-2) and ending at 1696 (n126-1)\n",
      "  warnings.warn(msg)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/partitura/directions.py:533: UserWarning: error parsing \"ritenuto\" (UnexpectedCharacters)\n",
      "  warnings.warn('error parsing \"{}\" ({})'.format(string, type(e).__name__))\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = create_data(files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "PAD = \"<PAD>\"\n",
    "\n",
    "PITCHES = {\n",
    "\t0: [\"C\", \"B#\", \"D--\"],\n",
    "\t1: [\"C#\", \"B##\", \"D-\"],\n",
    "\t2: [\"D\", \"C##\", \"E--\"],\n",
    "\t3: [\"D#\", \"E-\", \"F--\"],\n",
    "\t4: [\"E\", \"D##\", \"F-\"],\n",
    "\t5: [\"F\", \"E#\", \"G--\"],\n",
    "\t6: [\"F#\", \"E##\", \"G-\"],\n",
    "\t7: [\"G\", \"F##\", \"A--\"],\n",
    "\t8: [\"G#\", \"A-\"],\n",
    "\t9: [\"A\", \"G##\", \"B--\"],\n",
    "\t10: [\"A#\", \"B-\", \"C--\"],\n",
    "\t11: [\"B\", \"A##\", \"C-\"],\n",
    "}\n",
    "\n",
    "INTERVALS = {\n",
    "\t0: [\"P1\", \"d2\", \"A7\"],\n",
    "\t1: [\"m2\", \"A1\"],\n",
    "\t2: [\"M2\", \"d3\", \"AA1\"],\n",
    "\t3: [\"m3\", \"A2\"],\n",
    "\t4: [\"M3\", \"d4\", \"AA2\"],\n",
    "\t5: [\"P4\", \"A3\"],\n",
    "\t6: [\"d5\", \"A4\"],\n",
    "\t7: [\"P5\", \"d6\", \"AA4\"],\n",
    "\t8: [\"m6\", \"A5\"],\n",
    "\t9: [\"M6\", \"d7\", \"AA5\"],\n",
    "\t10: [\"m7\", \"A6\"],\n",
    "\t11: [\"M7\", \"d1\", \"AA6\"],\n",
    "}\n",
    "\n",
    "DIATONIC_PITCHES = [\"C\", \"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "KEY_SIGNATURES = list(range(-7, 8))\n",
    "accepted_pitches = [ii for i in PITCHES.values() for ii in i]\n",
    "accepted_ks = KEY_SIGNATURES\n",
    "pitch_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "ks_to_ix = {k: KEY_SIGNATURES.index(k) for k in KEY_SIGNATURES}\n",
    "# add PADDING TAD\n",
    "pitch_to_ix[PAD] = len(accepted_pitches)\n",
    "ks_to_ix[PAD] = len(KEY_SIGNATURES)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "class PKSpell(nn.Module):\n",
    "\t\"\"\"Models that decouples key signature estimation from pitch spelling by adding a second RNN.\n",
    "\tThis model reached state of the art performances for pitch spelling.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tinput_dim=3,\n",
    "\t\thidden_dim=100,\n",
    "\t\tpitch_to_ix=pitch_to_ix,\n",
    "\t\thidden_dim2=24,\n",
    "\t\trnn_depth=1,\n",
    "\t\tdropout=0.1,\n",
    "\t\tbidirectional=True\n",
    "\t):\n",
    "\t\tsuper(PKSpell, self).__init__()\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\tself.n_out_pitch = len(pitch_to_ix)\n",
    "\t\tself.hidden_dim = hidden_dim\n",
    "\t\tself.hidden_dim2 = hidden_dim2\n",
    "\n",
    "\t\t# RNN layer.\n",
    "\t\tself.rnn = nn.LSTM(\n",
    "\t\t\tinput_size=input_dim,\n",
    "\t\t\thidden_size=hidden_dim // 2 if bidirectional else hidden_dim,\n",
    "\t\t\tbidirectional=bidirectional,\n",
    "\t\t\tnum_layers=rnn_depth,\n",
    "\t\t)\n",
    "\t\t# Output layers.\n",
    "\t\tself.top_layer_pitch = nn.Linear(hidden_dim, self.n_out_pitch)\n",
    "\t\t# Loss function that we will use during training.\n",
    "\t\tself.loss_pitch = nn.CrossEntropyLoss()\n",
    "\n",
    "\tdef compute_outputs(self, sentences, sentences_len):\n",
    "\t\trnn_out, _ = self.rnn(sentences)\n",
    "\t\trnn_out = self.dropout(rnn_out)\n",
    "\t\tout_pitch = self.top_layer_pitch(rnn_out)\n",
    "\t\treturn out_pitch\n",
    "\n",
    "\tdef forward(self, sentences, pitches, sentences_len):\n",
    "\t\t# First computes the predictions, and then the loss function.\n",
    "\n",
    "\t\t# Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "\t\tscores_pitch = self.compute_outputs(sentences, sentences_len)\n",
    "\n",
    "\t\t# Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "\t\t# The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "\t\tscores_pitch = scores_pitch.view(-1, self.n_out_pitch)\n",
    "\t\tpitches = pitches\n",
    "\t\tloss = self.loss_pitch(scores_pitch, pitches)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef predict(self, sentences, sentences_len):\n",
    "\t\t# Compute the outputs from the linear units.\n",
    "\t\tscores_pitch, scores_ks = self.compute_outputs(sentences, sentences_len)\n",
    "\n",
    "\t\t# Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "\t\tpredicted_pitch = scores_pitch.argmax(dim=2)\n",
    "\t\treturn [predicted_pitch[: int(l), i].cpu().numpy() for i, l in enumerate(sentences_len)]\n",
    "\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "\tdef __init__(self, x, y):\n",
    "\t\tsuper(PSDataset, self).__init__()\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\treturn torch.tensor(self.x[idx]), torch.tensor(self.y[idx])\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)\n",
    "\n",
    "def collate_ps(data):\n",
    "\tdef merge(sequences):\n",
    "\t\tlengths = [len(seq) for seq in sequences]\n",
    "\t\tpadded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
    "\t\tfor i, seq in enumerate(sequences):\n",
    "\t\t\tend = lengths[i]\n",
    "\t\t\tpadded_seqs[i, :end] = seq[:end]\n",
    "\t\treturn sequences, lengths\n",
    "\n",
    "\t# sort a list by sequence length (descending order) to use pack_padded_sequence\n",
    "\tdata.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "\t# seperate source and target sequences\n",
    "\tsrc_seqs, trg_seqs = zip(*data)\n",
    "\n",
    "\t# merge sequences (from tuple of 1D tensor to 2D tensor)\n",
    "\t# src_seqs, src_lengths = merge(src_seqs)\n",
    "\t# trg_seqs, trg_lengths = merge(trg_seqs)\n",
    "\tsrc_lengths = [len(seq) for seq in src_seqs]\n",
    "\n",
    "\treturn src_seqs[0].float(), src_lengths, trg_seqs[0]\n",
    "\n",
    "class PKSpellPL(pl.LightningModule):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(PKSpellPL, self).__init__()\n",
    "\t\tself.module = PKSpell()\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tsrc_seqs, src_lengths, trg_seqs = batch\n",
    "\t\tloss = self.module(src_seqs, trg_seqs, src_lengths)\n",
    "\t\tself.log(\"train_loss\", loss.item(), on_epoch=True, on_step=True, prog_bar=True)\n",
    "\t\treturn loss\n",
    "\tdef val_step(self, batch, batch_idx):\n",
    "\t\tsrc_seqs, src_lengths, trg_seqs = batch\n",
    "\t\tloss = self.module(src_seqs, trg_seqs, src_lengths)\n",
    "\t\tself.log(\"val_loss\", loss.item(), on_epoch=True, prog_bar=True)\n",
    "\t\treturn loss\n",
    "\tdef configure_optimizers(self):\n",
    "\t\toptimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\t\treturn {\n",
    "\t\t\t\"optimizer\": optimizer,\n",
    "\t\t}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the PKSpell model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = PKSpellPL()\n",
    "train_dataloader = DataLoader(PSDataset(X_train, y_train), collate_fn=collate_ps, batch_size=1, num_workers=2)\n",
    "val_dataloader = DataLoader(PSDataset(X_test, y_test), collate_fn=collate_ps, batch_size=1, num_workers=2)\n",
    "trainer = pl.Trainer(max_epochs=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:105: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "\n",
      "  | Name   | Type    | Params\n",
      "-----------------------------------\n",
      "0 | module | PKSpell | 25.6 K\n",
      "-----------------------------------\n",
      "25.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n",
      "/home/manos/miniconda3/envs/partitura_tutorial/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42bdb76b8f83474caf79895f0f666b10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Voice Separation\n",
    "\n",
    "Here we will investigate the task of voice separation from Midi. This task consists of assigning a voice to each monophonic line."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class UnetVoiceSeparationModel(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 input_channels = 1,\n",
    "                 lr=0.0005,\n",
    "                 weight_decay=5e-4,\n",
    "        ):\n",
    "        super(UnetVoiceSeparationModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.module = UNet(input_channels, n_classes).double()\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.train_loss = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pr_dict = batch[0]\n",
    "        voice_pr = pr_dict[\"voice_pianoroll\"].squeeze().T\n",
    "        input_pr = torch.clip(voice_pr + 1, 0, 1).unsqueeze(0).unsqueeze(0).to(self.device, dtype = torch.float64)\n",
    "        labels = voice_pr.to(self.device).unsqueeze(0)\n",
    "\n",
    "        pred = self.module(input_pr)\n",
    "        loss = self.train_loss(pred, labels)\n",
    "        # batch_f1 = self.train_f1(batch_pred, batch_labels)\n",
    "        self.log(\"train_loss\", loss.item(), prog_bar=True, on_epoch=True, on_step = True, batch_size = 1, sync_dist=True)\n",
    "        # self.log(\"train_f1\", batch_f1.item(), prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pr_dict = batch[0]\n",
    "        voice_pr = pr_dict[\"voice_pianoroll\"].squeeze().T\n",
    "        input_pr = torch.clip(voice_pr + 1, 0, 1).unsqueeze(0).unsqueeze(0).to(self.device, dtype = torch.float64)\n",
    "        labels = voice_pr.to(self.device).unsqueeze(0)\n",
    "\n",
    "        pred = self.module(input_pr)\n",
    "        loss = self.train_loss(pred, labels)\n",
    "        self.log(\"val_loss\", loss.item(), prog_bar=True, on_epoch=True, on_step = True, batch_size = 1)\n",
    "        voice_pred = pr_to_voice_pred(F.log_softmax(pred.squeeze(), dim = 0), pr_dict[\"notearray_onset_beat\"].squeeze(), pr_dict[\"notearray_duration_beat\"].squeeze(),  pr_dict[\"notearray_pitch\"].squeeze(), piano_range=True, time_div = 12)\n",
    "        voice_pred = voice_pred.to(self.device)\n",
    "        fscore = self.val_monophonic_f1(voice_pred, pr_dict[\"notearray_voice\"].squeeze(), pr_dict[\"notearray_onset_beat\"].squeeze(), pr_dict[\"notearray_duration_beat\"].squeeze())\n",
    "        self.log(\"val_f1\", fscore.item(), prog_bar=True, on_epoch=True, on_step = True, batch_size = 1, sync_dist=True)\n",
    "        avc = self.val_avc(voice_pred, pr_dict[\"notearray_voice\"].squeeze())\n",
    "        self.log(\"val_avc\", avc.item(), prog_bar=True, on_epoch=True, on_step = True, batch_size = 1, sync_dist=True)\n",
    "        # add F1 computation\n",
    "        return avc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
